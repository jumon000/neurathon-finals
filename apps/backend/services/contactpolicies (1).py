# -*- coding: utf-8 -*-
"""contactPolicies.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hcTIKR2YC2bruQG567nG8mfV4cg_q4b-
"""

!pip install spacy pymupdf python-docx nltk gensim scikit-learn sentence-transformers
!python -m spacy download en_core_web_sm

import fitz  # PyMuPDF for PDF handling
import docx
import nltk
import spacy
import numpy as np
import re
from sentence_transformers import SentenceTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from collections import defaultdict

# Download required resources
nltk.download("punkt")
nltk.download('punkt_tab')
nltk.download("stopwords")
nlp = spacy.load("en_core_web_sm")

# Load Transformer Model for embeddings
model = SentenceTransformer("all-MiniLM-L6-v2")


# 1Ô∏è‚É£ READ TEXT FROM FILES
def read_file(file_path):
    text = ""
    if file_path.endswith(".txt"):
        with open(file_path, "r", encoding="utf-8") as f:
            text = f.read()
    elif file_path.endswith(".pdf"):
        doc = fitz.open(file_path)
        for page in doc:
            text += page.get_text("text") + "\n"
    elif file_path.endswith(".docx"):
        doc = docx.Document(file_path)
        text = "\n".join([para.text for para in doc.paragraphs])
    return text.strip()

# 2Ô∏è‚É£ EXTRACT NAMED ENTITIES (NER)
def extract_ner(text):
    doc = nlp(text)
    entities = defaultdict(set)
    for ent in doc.ents:
        entities[ent.label_].add(ent.text)
    return {k: list(v) for k, v in entities.items()}

# 3Ô∏è‚É£ EXTRACT CONTRACT STRUCTURE (SECTIONS)
def extract_sections(text):
    sections = re.findall(r"(Section \d+: [^\n]+)", text)
    return sections if sections else ["No sections found"]

# 4Ô∏è‚É£ EXTRACT KEY CONTRACTUAL CLAUSES
def extract_clauses(text):
    clauses = {
        "Scope of Work": re.findall(r"(Scope of Work.*?)(?:Section|\Z)", text, re.DOTALL),
        "Termination Clause": re.findall(r"(Termination.*?)(?:Section|\Z)", text, re.DOTALL),
        "Renewal Clause": re.findall(r"(Contract Renewal.*?)(?:Section|\Z)", text, re.DOTALL),
        "Financial Terms": re.findall(r"(Purchase Order.*?)(?:Section|\Z)", text, re.DOTALL),
    }
    return {k: v[0] if v else "Not Found" for k, v in clauses.items()}

# 5Ô∏è‚É£ MAIN FUNCTION TO RUN ALL EXTRACTIONS
def extract_contract_features(file_path):
    text = read_file(file_path)

    features = {
        "Named Entities": extract_ner(text),
        "Sections": extract_sections(text),
        "Clauses": extract_clauses(text),
    }

    return features, text  # Returning raw text for LLM input

# 6Ô∏è‚É£ EXAMPLE USAGE
if __name__ == "__main__":
    file_path = "/content/contract1.pdf"  # Replace with actual file path

    # Extract contract features
    features, document_text = extract_contract_features(file_path)

    # Print extracted features
    for key, value in features.items():
        print(f"\nüîπ {key}:")
        print(value)

    # Save extracted text for LLM processing
    with open("contract_text.txt", "w", encoding="utf-8") as f:
        f.write(document_text)

    print("\n‚úÖ Extracted contract text saved for LLM processing.")

